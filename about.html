<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About - MLC</title>
    <link rel="stylesheet" href="css/style.css">
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <script src="js/includes.js" defer></script>
</head>
<body>
    <div id="site-header"></div>

    <main>
        <!-- Page Header -->
        <section class="page-header">
            <div class="container">
                <h1 class="page-title">About MLC</h1>
                <p class="page-description">
                    Learn about our mission to democratize AI through machine learning compilation
                    and systems co-design, enabling high-performance deployment of AI models.
                </p>
            </div>
        </section>

        <!-- Mission Section -->
        <section class="mission">
            <div class="container">
                <div class="mission-content">
                    <div class="mission-text">
                        <h2>Our Mission</h2>
                        <p class="mission-lead">
                            MLC is dedicated to democratizing artificial intelligence by making
                            high-performance model development and deployment accessible to everyone,
                            everywhere, on any device.
                        </p>
                        <p>
                            We focus on compiler-driven and system-level innovations that unlock efficient AI across
                            platforms. While we highlight modern LLM workloads, our work spans a broad range of models
                            including vision, speech, and multimodal applications. Our goal is to empower developers,
                            researchers, and organizations to deploy advanced AI—from laptops and phones to the cloud
                            and edge—while maintaining exceptional performance, efficiency, and privacy.
                        </p>
                        <div class="mission-values">
                            <div class="value-item">
                                <i class="fas fa-universal-access"></i>
                                <h4>Accessibility</h4>
                                <p>Making AI accessible to developers and users across all platforms and devices.</p>
                            </div>
                            <div class="value-item">
                                <i class="fas fa-lock"></i>
                                <h4>Privacy</h4>
                                <p>Enabling on-device inference to protect user privacy and data security.</p>
                            </div>
                            <div class="value-item">
                                <i class="fas fa-leaf"></i>
                                <h4>Efficiency</h4>
                                <p>Optimizing for minimal resource usage and maximum performance.</p>
                            </div>
                        </div>
                    </div>
                    <div class="mission-visual">
                        <div class="mission-diagram">
                            <div class="diagram-center">
                                <div class="center-icon">
                                    <i class="fas fa-brain"></i>
                                </div>
                                <span>MLC</span>
                            </div>
                            <div class="diagram-nodes">
                                <div class="node mobile">
                                    <i class="fas fa-mobile-alt"></i>
                                    <span>Mobile</span>
                                </div>
                                <div class="node desktop">
                                    <i class="fas fa-desktop"></i>
                                    <span>Desktop</span>
                                </div>
                                <div class="node server">
                                    <i class="fas fa-server"></i>
                                    <span>Server</span>
                                </div>
                                <div class="node edge">
                                    <i class="fas fa-microchip"></i>
                                    <span>Edge</span>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- History -->
        <section class="history">
            <div class="container">
                <h2 class="section-title">Our Journey</h2>
                <div class="timeline">
                    <div class="timeline-item">
                        <div class="timeline-date">2023 Q1</div>
                        <div class="timeline-content">
                            <h3>Project Inception</h3>
                            <p>MLC-LLM project began as a research initiative to optimize large language model inference for mobile and edge devices.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-date">2023 Q2</div>
                        <div class="timeline-content">
                            <h3>First Release</h3>
                            <p>Launched MLC-LLM v0.1.0 with basic inference capabilities and support for popular LLM architectures.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-date">2023 Q3</div>
                        <div class="timeline-content">
                            <h3>Mobile Support</h3>
                            <p>Introduced MLC-LLM Mobile framework enabling native iOS and Android deployment with optimized performance.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-date">2023 Q4</div>
                        <div class="timeline-content">
                            <h3>Community Growth</h3>
                            <p>Reached 1,000 GitHub stars and established active Discord community with 500+ members.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-date">2024 Q1</div>
                        <div class="timeline-content">
                            <h3>Production Serving</h3>
                            <p>Released MLC-LLM Serve for production-ready deployment with auto-scaling and load balancing.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-date">2024 Q2</div>
                        <div class="timeline-content">
                            <h3>Major Optimization</h3>
                            <p>Achieved 50% memory reduction and 2x inference speed improvement through advanced compilation techniques.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-date">2024 Q3</div>
                        <div class="timeline-content">
                            <h3>Enterprise Adoption</h3>
                            <p>Major tech companies began adopting MLC-LLM for production workloads, reaching 10,000+ GitHub stars.</p>
                        </div>
                    </div>
                    <div class="timeline-item">
                        <div class="timeline-date">2024 Q4</div>
                        <div class="timeline-content">
                            <h3>Current Milestone</h3>
                            <p>MLC-LLM v0.3.0 with breakthrough performance improvements and expanded hardware support.</p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Team Section -->
        <section class="team">
            <div class="container">
                <h2 class="section-title">Core Team</h2>
                <div class="team-grid">
                    <div class="team-member">
                        <div class="member-avatar">
                            <i class="fas fa-user"></i>
                        </div>
                        <h3>Dr. Tianqi Chen</h3>
                        <p class="member-role">Core Team · Carnegie Mellon University</p>
                        <p class="member-bio">
                            Creator of Apache TVM and XGBoost. Leads compiler and system innovations in MLC,
                            enabling efficient deployment of modern AI workloads including LLMs.
                        </p>
                        <div class="member-links">
                            <a href="https://tqchen.com" target="_blank" rel="noopener">
                                <i class="fas fa-globe"></i>
                            </a>
                            <a href="https://github.com/tqchen" target="_blank" rel="noopener">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    <div class="team-member">
                        <div class="member-avatar">
                            <i class="fas fa-user"></i>
                        </div>
                        <h3>Dr. Zhihao Jia</h3>
                        <p class="member-role">Core Team · Carnegie Mellon University</p>
                        <p class="member-bio">
                            Researches systems for ML and high-performance inference/serving. Contributes to
                            scalable execution and optimization across heterogeneous hardware.
                        </p>
                    </div>
                    <div class="team-member">
                        <div class="member-avatar">
                            <i class="fas fa-user"></i>
                        </div>
                        <h3>Dr. Xupeng Miao</h3>
                        <p class="member-role">Core Team · Purdue University</p>
                        <p class="member-bio">
                            Focuses on low-latency LLM serving and compiler-runtime co-design, including
                            speculative decoding and token-tree verification techniques.
                        </p>
                    </div>
                </div>
                
                <div class="team-note">
                    <p>
                        <strong>Join Our Team:</strong> We're always looking for talented developers, 
                        researchers, and contributors to join our mission. 
                        <a href="projects.html">Explore our projects</a> or 
                        <a href="courses.html">check out our tutorials</a> to learn more about our work.
                    </p>
                </div>
            </div>
        </section>

        <!-- Technology -->
        <section class="technology">
            <div class="container">
                <h2 class="section-title">Technology Stack</h2>
                <div class="tech-grid">
                    <div class="tech-category">
                        <h3>Core Technologies</h3>
                        <div class="tech-items">
                            <div class="tech-item">
                                <i class="fab fa-python"></i>
                                <span>Python</span>
                            </div>
                            <div class="tech-item">
                                <i class="fas fa-code"></i>
                                <span>C++</span>
                            </div>
                            <div class="tech-item">
                                <i class="fab fa-rust"></i>
                                <span>Rust</span>
                            </div>
                            <div class="tech-item">
                                <i class="fab fa-swift"></i>
                                <span>Swift</span>
                            </div>
                            <div class="tech-item">
                                <i class="fab fa-android"></i>
                                <span>Kotlin</span>
                            </div>
                        </div>
                    </div>
                    <div class="tech-category">
                        <h3>ML Frameworks</h3>
                        <div class="tech-items">
                            <div class="tech-item">
                                <i class="fas fa-brain"></i>
                                <span>TVM</span>
                            </div>
                            <div class="tech-item">
                                <i class="fab fa-pytorch"></i>
                                <span>PyTorch</span>
                            </div>
                            <div class="tech-item">
                                <i class="fas fa-project-diagram"></i>
                                <span>ONNX</span>
                            </div>
                            <div class="tech-item">
                                <i class="fas fa-cube"></i>
                                <span>TensorRT</span>
                            </div>
                        </div>
                    </div>
                    <div class="tech-category">
                        <h3>Hardware Support</h3>
                        <div class="tech-items">
                            <div class="tech-item">
                                <i class="fas fa-microchip"></i>
                                <span>NVIDIA GPU</span>
                            </div>
                            <div class="tech-item">
                                <i class="fab fa-apple"></i>
                                <span>Apple Silicon</span>
                            </div>
                            <div class="tech-item">
                                <i class="fas fa-mobile-alt"></i>
                                <span>ARM CPU</span>
                            </div>
                            <div class="tech-item">
                                <i class="fas fa-laptop"></i>
                                <span>x86 CPU</span>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Partners -->
        <section class="partners">
            <div class="container">
                <h2 class="section-title">Our Partners</h2>
                <p class="partners-description">
                    We're proud to collaborate with leading organizations and institutions 
                    that share our vision for democratizing AI.
                </p>
                <div class="partners-grid">
                    <div class="partner-card">
                        <div class="partner-logo">
                            <i class="fas fa-university"></i>
                        </div>
                        <h3>Carnegie Mellon University</h3>
                        <p>Research collaboration on machine learning compilation and optimization techniques.</p>
                    </div>
                    <div class="partner-card">
                        <div class="partner-logo">
                            <i class="fas fa-graduation-cap"></i>
                        </div>
                        <h3>University of Washington</h3>
                        <p>Joint research on mobile AI and edge computing optimization strategies.</p>
                    </div>
                    <div class="partner-card">
                        <div class="partner-logo">
                            <i class="fas fa-school"></i>
                        </div>
                        <h3>Purdue University</h3>
                        <p>Collaboration on low-latency serving systems and compiler-runtime co-design.</p>
                    </div>
                    <div class="partner-card">
                        <div class="partner-logo">
                            <i class="fas fa-building"></i>
                        </div>
                        <h3>Apache Software Foundation</h3>
                        <p>Integration with Apache TVM ecosystem for advanced compilation capabilities.</p>
                    </div>
                    <div class="partner-card">
                        <div class="partner-logo">
                            <i class="fas fa-cloud"></i>
                        </div>
                        <h3>Open Source Community</h3>
                        <p>Collaborative development with the broader open source AI community.</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Call to Action -->
        <section class="cta-section">
            <div class="container">
                <div class="cta-content">
                    <h2>Ready to Join Our Mission?</h2>
                    <p>
                            Whether you're a developer, researcher, or organization looking to leverage
                            AI technology, MLC provides the tools and community support you need.
                    </p>
                    <div class="cta-buttons">
                        <a href="projects.html" class="btn btn-primary">
                            <i class="fas fa-rocket"></i>
                            Get Started
                        </a>
                        <a href="courses.html" class="btn btn-secondary">
                            <i class="fas fa-graduation-cap"></i>
                            View Courses
                        </a>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <div id="site-footer"></div>

    <script src="js/script.js"></script>
</body>
</html>

